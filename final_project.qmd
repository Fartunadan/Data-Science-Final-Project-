---
title: "Final Project"
author: "Fartun, Daija, and Kaela"
format: html
embed-resources: true
execute:
  warning: false
  message: false
editor: visual
---

# Rent Burden in America

```{r}
#| message: false
#| warning: false
#| echo: false # how do I hide this code?
knitr::include_graphics("image01.avif")
```

## Problem Statement:

Housing affordability has reached a critical juncture for American renters.

-   Between 2021 and 2023, the number of cost-burdened renter households those spending more than 30% of their income on rent and utilities climbed to an unprecedented 22.6 million, with 12.1 million households severely burdened by spending over half their income on housing.

-   Nearly half of all renter households now face cost burden, and these impacts fall disproportionately across racial lines, exacerbating existing inequalities.

This escalating crisis threatens not only individual financial stability but also broader economic health, as families sacrifice spending on healthcare, education, and savings to maintain shelter. Understanding the drivers and patterns of rent burden is essential for policymakers, housing advocates, and community planners to develop targeted interventions. A predictive model addressing rent burden can identify at-risk populations, forecast future trends, and inform evidence-based policies to prevent millions more households from falling into financial precarity. Without such tools, responses remain reactive rather than preventive, leaving vulnerable communities increasingly exposed to housing instability and its cascading consequences.

## Research Question: Predicting Household Rent Burden

**Primary Research Question:** Can we develop a model that adequately predicts a household's rent burden status using socioeconomic and demographic characteristics?

**Secondary Research Question:** Which variables are the most important in predicting the extent to which a household is rent burdened?

*Model Development:*

-   What combination of socioeconomic and demographic factors best predicts rent burden status?

-   How accurately can we classify households into burden categories (not burdened, burdened, severely burdened)?

-   Which modeling approaches (Linear regression, decision tree, random forest, etc.) provide optimal predictive performance?

## Data

The data were pulled from the IPUMS ACS 2023 microdata and the sample is limited to individuals that indicated they rent their dwelling. The dataset needs to be collapsed so that the unit of observation is the household.

```{r}
#Note: in this section, we need to clean the dataset, collapse it to the household level and then separate it into training and testing data. Then, we can do 2-3 visuals for exploratory data analysis.

library(tidyverse)
library(tidymodels)
library(rpart.plot)
library(vip)
library(haven)

data <- read_dta("data/ACS_extract.dta")
acs2023 <- data |>
  filter(ownershpd == 22 & hhincome > 0) |> #keep those who rent "with cash" and those with positive household income
  select(-cbserial, -year, -sample, -gq, -ownershp, -ownershpd, -multgend, -perwt, -related, -raced, -hispand, -empstatd) |>
  filter(statefip == 12)

#creating new household level variables based on composition

acs2023 <- acs2023 |>
  group_by(serial) |>
  mutate(prop_female = mean(sex == 2, na.rm = TRUE),
         mean_age = mean(age, na.rm = TRUE),
         prop_adult = mean(age >= 18, na.rm = TRUE),
         prop_healthcare = mean(hcovany == 2, na.rm = TRUE))|>
  ungroup()
         
acs2023 <- acs2023 |>
  group_by(serial) |>
  mutate(prop_white = mean(race == 1, na.rm = TRUE),
            prop_black = mean(race == 2, na.rm = TRUE),
            prop_ai_an = mean(race == 3, na.rm = TRUE),
            prop_asian = mean(race == 4| race == 5| race == 6, na.rm = TRUE)) |>
  ungroup()

acs2023 <- acs2023 |>
  group_by(serial) |>
  mutate(prop_hispanic = mean(hispan >0 & hispan < 9, na.rm = TRUE),
         prop_citizen = mean(citizen == 0 | citizen == 1| citizen == 2, na.rm = TRUE),
         prop_hsgrad = sum(educd >= 62 & age >= 18, na.rm = TRUE) / sum(age >=18), 
         prop_colgrad = sum(educd >= 101 & age >= 18, na.rm = TRUE) / sum(age >=18)) |>
  ungroup()

acs2023 <- acs2023 |>
  group_by(serial) |>
  mutate(prop_empstat = sum (empstat == 1  & age >= 16, na.rm = TRUE)/ sum(age >=16),
         total_hrs = sum(uhrswork, na.rm = TRUE)) |>
  ungroup()

# getting the data to the household level now and creating rent burden variables
acs_household <- acs2023 |>
  filter(relate == 1) |>
  select(-relate, -sex, -age, -race, -hispan, -citizen, -hcovany, -empstat, -uhrswork) |>
  mutate(rent_income = (rentgrs*12)/hhincome,
         rent_burden = if_else(rent_income > .3, 1, 0),
         rent_burdend = case_when(
           rent_income > .5 ~ "extremely rent burdened",
           rent_income > .3 ~ "rent burdened",
           rent_income <= .3 ~ "not rent burdened"
         ),
         rent_burdend = factor(rent_burdend, levels = c("not rent burdened", "rent burdened", "extremely rent burdened"), ordered = TRUE))

acs_household |>
  count(rent_burdend)
#next steps:
#convert remaining categorical variables to unordered factors?
#hhtype, cbhhtype, region, statefip, countyfip, metro, city, marst, educ
# might need to recode bedrooms because wtf ("to get the actual number of bedrooms, users must subtract 1 from the value of BEDROOMS")
#get rid of the rent_income, grsrent, hhincome variables before we can split into training and testing

```

## Models

```{r}
#This is where we'll create a recipe or two for our outcome variables. One will use the dummy as the outcome and drop the factor, and the other will use the factor as the outcome and drop the dummy. I think in the above section, after creating these two variables, we should drop the rent variable and the household income variable because we want to predict rent burden and if we had that information we'd just be able to predict it.

#setseed
#split data to training and testing (default)
#recipe:
  #think of steps to include in the recipe

#model 1: Decision tree w/ dummy variable : 3 hyper parameters(cost complexity, treedepth,min n  )

#Model 2: Decision tree w/ factor variable 


#model 3: Either Lasso or elastic net ; justify reason for model
# tune for penalty -- suggesting elastic net 






```

## Analysis

```{r}
length(unique(acs2023$serial))
```

## Findings/Results

## Conclusions and Recommendations
